# Improved Precision and Recall Metric for Assessing Generative Models 

This project is done as a part of the deep learning interview stage for NAVER Corp. It is mostly based on the [paper](https://arxiv.org/pdf/1904.06991.pdf) with the same name. The paper provides an improved precision and recall metric for General Adversarial Networks(GANs) using a binary function and k-nearest neighbors. The interviewer asked to calculate the precision and recall metric defined in this paper by applying it to two sets of 10000 images from a dataset such as celebA or CIFAR-10, and then explain the precision and recall values alongside in-depth analysis.

## Calculation Process

Within the paper provided, the metrics were calculated by comparing a set of feature vectors from a distribution of real images and a distribution of generated images. The images were generated by using a StyleGAN provided by NVIDIA, and the feature vectors were extracted from a pre-trained VGG-16 classifier. In this project, we try to replicate the paper's experiments, but we use a Deep Convolutional Generative Adversarial Network (DCGAN) instead of a StyleGAN. 

The project contains two Python files.

### calculate.py

The calculate.py file then extracts the feature vector from the image files using the pretrained model of VGG16. It then estimates the manifold using k-NN neighbors and returns the precision and recall value. The function pretrained_model in calculate.py makes use of the VGG16 from Keras (with additional layers : based on [this thread](https://github.com/keras-team/keras/issues/4465)), which is used to extract feature vectors of each image. Using the feature vectors extracted from this step, the manifold_estimator function tries to estimate the true manifold of of the data using k-neareest neighbors, and returns the fraction value of feature vectors that lie within the estimated manifold. The knn_precision_recall function then calculates the precision and recall value of the real and generated images. These functions were designed by following the pseudo-code provided in Appendix A in the aforementioned [paper](https://arxiv.org/pdf/1904.06991.pdf). 

### generate_image.py 

The generate_image.py file generates a number of images that has been trained by a DCGAN, and returns 10000 generated images. The whole code is based on [this notebook](https://github.com/naokishibuya/deep-learning/blob/master/python/dcgan_celeba.ipynb) with several adjustments, which proposes a DCGAN using the same celebA dataset. 

## Results and Analysis

This author wanted to generate 10000 images from a DCGAN and then calculate the precision and recall values of a set of 10000 images from celebA and the 10000 generated images, but the time it took to train a DCGAN using approximately 200000 images from celebA, and then calculating the feature vectors for each of the 10000 images took more than 8 hours. Hence, for practical computational purposes, the author will calculate the precision and recall values of the first 20000 images in the celebA dataset. (The code to calculate the precision and recall values for the celebA dataset images and the images generated by the DCGAN is commented in calculate.py)

By definition, precision is the fraction of the generated images that are realistic, and recall is the fraction of the training data within the manifold covered by the generator. In other words, a high precision value indicates a high quality of generated samples, and a high recall value implies that the generator can generate many realistic samples found in the "real" image distribution. 

An exemplary example of illustrating precision and recall is provided by [this paper](https://arxiv.org/pdf/1711.10337.pdf), which also explores evaluation measures of a GAN. 

The precision and recall code has been repeated several times, using the first 10000 images as the "real images" and the next 10000 images as the "generated images". Overall the results return consistent  values of precision and recall : the precision value lies between 0.6 ~ 0.7, and the recall value lies between 0.5 ~ 0.6. A fairly high value of precision implies that the "generated image" set contains a high quality of images, which is expected as we are using the images of celebA as a substitute of the "generated images". A considerable recall value can be attributed to the variation within the images in celebA, as often variation within a dataset also improves recall. 

In practice, however, it is not easy to provide a clear interpretation of the values, given that due to time constraints and computational limitations we are not using generated images from GANs, but instead using substitute images from the same training dataset. 

## Conclusion

There is no exclusive way to measure the performances of a Generative Adversarial Network that has been defined yet. However, the precision and recall calculation method provided by within this [paper](https://arxiv.org/pdf/1904.06991.pdf) shows strong promise of further developments in assessing generative models. This project tries to replicate what the improved precision and recall metric provided within the paper, and calculates the values of precision and recall using the celebA dataset. 


## Acknowledgements and References 

